import openai
import csv
import time
import re
import os 
from dotenv import load_dotenv

# ENV íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
load_dotenv()
API_KEY = os.environ.get("API_KEY")

# OpenAI API Key ì„¤ì •
openai.api_key = API_KEY

# ì£¼ì œë³„ í”„ë¡¬í”„íŠ¸ ì •ì˜
topics = ["ê°ì •", "ë™ë¬¼", "ìì—°", "ìŒì‹", "í™œë™", "ì§ì—…", "ì—¬í–‰", "ì¥ì†Œ", "ì§ì—…", "ì‚¬ë¬¼", "êµ­ê°€", "ì‚¬ê³„ì ˆ", "ì¼ìƒ", "ê²½í—˜"]


# CSV íŒŒì¼ ì €ì¥ ê²½ë¡œ
csv_filename = "test.csv"

# API ìš”ì²­ì„ ë³´ë‚´ëŠ” í•¨ìˆ˜
def generate_sentences(topic, n=2):  # ê° í† í”½ë³„ë¡œ nê°œ ìƒì„±
    prompt = (
        f"{topic}ì— ëŒ€í•´ ì„¤ëª…í•˜ëŠ” ì™„ì „í•˜ê³  ì˜¨ì „í•œ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. "
        "ê° ë¬¸ì¥ë³„ ì‘ë‹µ í˜•ì‹: "
        f"(ë¬¸ì¥):(ì´ëª¨ì§€ ì‹œí€€ìŠ¤):{topic}. "
        "ì‘ë‹µ ì˜ˆì‹œ: "
        f"ë°¤í•˜ëŠ˜ì„ ë³´ë©´ì„œ í‰í™”ë¡œì›€ì„ ëŠê¼ˆì–´:ğŸŒ™âœ¨ğŸ‘€ğŸ§˜â€â™‚ï¸:{topic}. "
        f"ëˆˆì´ ë„ˆë¬´ ë‚´ë ¤ì„œ ì–¼ì–´ ì£½ëŠ”ì¤„ ì•Œì•˜ì–´:â„ï¸ğŸŒ¨ï¸ğŸ¥¶:{topic}. "
        "ì°½ì˜ì ì´ê³  ë¹„ìœ ì ì´ë©° í•œ ë¬¸ì¥ë‹¹ ì´ëª¨ì§€ ìµœì†Œ 2ê°œì—ì„œ ìµœëŒ€ 20ê°œì˜ ì‘ë‹µì´ ìƒì„±ë©ë‹ˆë‹¤. "
        f"ì´ëª¨ì§€ ì‚¬ìš©ì‹œ {topic}ê³¼ ê´€ë ¨ëœ ì¹´í…Œê³ ë¦¬ì˜ ì´ëª¨ì§€ë¥¼ í•„ìˆ˜ë¡œ í¬í•¨í•©ë‹ˆë‹¤."
    )

# CSV íŒŒì¼ì„ append ëª¨ë“œë¡œ ì—´ê¸°
    with open(csv_filename, mode='a', newline='', encoding='utf-8') as file:  
        writer = csv.writer(file)
        
        # íŒŒì¼ì´ ì²˜ìŒ ìƒì„±ë˜ë©´ í—¤ë” ì¶”ê°€
        if file.tell() == 0:  # íŒŒì¼ì˜ ìœ„ì¹˜ê°€ 0ì¼ ë•Œ í—¤ë” ì‘ì„±
            writer.writerow(["text", "emoji", "topic"])  # CSV íŒŒì¼ì— í—¤ë” ì¶”ê°€ (í•œë²ˆë§Œ)
        
        for _ in range(n):
            try:
                # GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬¸ì¥ ë° ì´ëª¨ì§€ ì‹œí€€ìŠ¤ ìƒì„±
                response = openai.ChatCompletion.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=170,
                    temperature=1.0,
                )
                
                # ì‘ë‹µ ë‚´ìš© í™•ì¸ ë° ë°”ë¡œ ì €ì¥ ì¤€ë¹„
                generated_text = response['choices'][0]['message']['content'].strip()
                print(f"{generated_text}")  # ì‘ë‹µì„ ì½˜ì†”ì— ì¶œë ¥
                
                # ë¬¸ì¥ì´ ì—¬ëŸ¬ ê°œì¼ ê²½ìš° êµ¬ë¶„ì '.'ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                sentences = generated_text.split('.')
                for sentence in sentences:
                    if ':' in sentence:
                        parts = sentence.split(':')
                        if len(parts) == 3:  # ì •í™•í•˜ê²Œ ì„¸ ë¶€ë¶„ìœ¼ë¡œ ë¶„ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                            text, emojis, topic = parts[0].strip(), parts[1].strip(), parts[2].strip()

                            if len(emojis) > 1:
                                writer.writerow([text, emojis, topic])  # ë°”ë¡œ CSV íŒŒì¼ì— ì €ì¥
                                # print(f"Saved: {text}, {emojis}, {topic}")
                            else:
                                print(f"Skipping entry: Not enough emojis for topic {topic}")
                        else:
                            print(f"Skipping entry: Incorrect format in response for topic {topic}")
                    else:
                        print(f"Skipping entry: No proper format found in response for topic {topic}")
                    time.sleep(1)
            except Exception as e:
                print(f"Error generating text for topic {topic}: {e}")
                continue

# # ì£¼ì œë³„ë¡œ ëŒì•„ê°€ë©´ì„œ ë¬¸ì¥ ìƒì„±
def generate_sentences_across_topics(topics, n_per_topic):
    total_generated = 0
    while total_generated < n_per_topic * len(topics):
        for topic in topics:
            generate_sentences(topic, n=1)  # í•œ ë²ˆì— ê° í† í”½ë³„ë¡œ í•˜ë‚˜ì”© ìƒì„±
            total_generated += 1
            if total_generated >= n_per_topic * len(topics):
                break

# # ë¬¸ì¥ ìƒì„± ì‹¤í–‰
generate_sentences_across_topics(topics, 3)

print(f"Data saved to {csv_filename}")